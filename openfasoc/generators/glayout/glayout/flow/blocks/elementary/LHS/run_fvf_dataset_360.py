#!/usr/bin/env python3
"""
FVF Dataset Generator using pre-generated LHS parameters (360 samples).
Uses the fvf_parameters.json file generated by elhs.py.
"""

import logging
import os
import sys
import time
import json
import shutil
from pathlib import Path
import numpy as np
import pandas as pd

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def setup_environment():
    """Set up the PDK environment"""
    pdk_root = "/opt/conda/envs/GLdev/share/pdk"
    os.environ['PDK_ROOT'] = pdk_root
    os.environ['PDKPATH'] = pdk_root
    os.environ['PDK'] = 'sky130A'
    return pdk_root

def robust_flipped_voltage_follower(pdk, **params):
    """Robust wrapper around flipped_voltage_follower that handles pydantic issues"""
    from fvf import flipped_voltage_follower
    
    # Try the normal approach first
    try:
        return flipped_voltage_follower(pdk=pdk, **params)
    except Exception as e:
        if "validation error" in str(e).lower() or "pydantic" in str(e).lower():
            logger.warning(f"Pydantic validation error, trying workaround")
            
            # Workaround: Create a new PDK object with fresh properties
            try:
                # Get the PDK class
                from glayout.flow.pdk.mappedpdk import MappedPDK
                
                # Create a new instance with the same properties
                new_pdk = MappedPDK(
                    process_name=pdk.process_name,
                    tech_dir=pdk.tech_dir,
                    models_file=pdk.models_file,
                    drc_runset=pdk.drc_runset,
                    lvs_runset=pdk.lvs_runset,
                    pex_runset=pdk.pex_runset
                )
                
                return flipped_voltage_follower(pdk=new_pdk, **params)
            except Exception as e2:
                logger.warning(f"Fresh PDK approach failed, trying dict workaround: {e2}")
                
                # Last resort: convert to dict and create basic object
                try:
                    pdk_dict = {
                        'process_name': getattr(pdk, 'process_name', 'sky130A'),
                        'tech_dir': getattr(pdk, 'tech_dir', '/opt/conda/envs/GLdev/share/pdk/sky130A'),
                        'models_file': getattr(pdk, 'models_file', ''),
                        'drc_runset': getattr(pdk, 'drc_runset', ''),
                        'lvs_runset': getattr(pdk, 'lvs_runset', ''),
                        'pex_runset': getattr(pdk, 'pex_runset', '')
                    }
                    
                    class SimplePDK:
                        def __init__(self, **kwargs):
                            for k, v in kwargs.items():
                                setattr(self, k, v)
                    
                    simple_pdk = SimplePDK(**pdk_dict)
                    return flipped_voltage_follower(pdk=simple_pdk, **params)
                except Exception as e3:
                    logger.error(f"All PDK workarounds failed: {e3}")
                    raise e3
        else:
            logger.error(f"Non-pydantic error in FVF generation: {e}")
            raise e

def load_fvf_parameters():
    """Load the pre-generated FVF parameters from JSON file"""
    param_file = Path(__file__).parent / "generated_parameters" / "fvf_parameters.json"
    
    if not param_file.exists():
        raise FileNotFoundError(f"FVF parameters file not found: {param_file}")
    
    with open(param_file, 'r') as f:
        parameters = json.load(f)
    
    logger.info(f"Loaded {len(parameters)} FVF parameter sets from {param_file}")
    return parameters

def run_single_evaluation(trial_num, params, output_dir):
    """Run a single FVF evaluation with robust error handling"""
    trial_start = time.time()
    
    try:
        # Setup environment
        setup_environment()
        
        # Get PDK object
        from glayout.flow.pdk.sky130_mapped import sky130_mapped_pdk
        pdk = sky130_mapped_pdk
        
        # Create component with robust wrapper
        logger.debug(f"Running sample {trial_num:04d} with params: {params}")
        component = robust_flipped_voltage_follower(pdk=pdk, **params)
        
        # Create sample directory
        trial_dir = Path(output_dir) / f"sample_{trial_num:04d}"
        trial_dir.mkdir(exist_ok=True)
        
        # Generate GDS file
        gds_file = trial_dir / f"fvf_sample_{trial_num:04d}.gds"
        component.write_gds(str(gds_file))
        
        # Run verification with robust error handling
        from robust_verification import run_robust_verification
        
        verification_results = run_robust_verification(
            str(gds_file), 
            str(trial_dir / f"fvf_sample_{trial_num:04d}"),
            component  # Pass the component as top_level
        )
        
        drc_result = verification_results["drc"]["is_pass"]
        lvs_result = verification_results["lvs"]["is_pass"]
        
        trial_time = time.time() - trial_start
        
        result = {
            "sample_id": trial_num,
            "component_name": f"fvf_sample_{trial_num:04d}",
            "success": True,
            "drc_pass": drc_result,
            "lvs_pass": lvs_result,
            "execution_time": trial_time,
            "parameters": params,
            "output_directory": str(trial_dir)
        }
        
        logger.info(f"✅ Sample {trial_num:04d} completed in {trial_time:.1f}s (DRC: {'✓' if drc_result else '✗'}, LVS: {'✓' if lvs_result else '✗'})")
        return result
        
    except Exception as e:
        trial_time = time.time() - trial_start
        logger.error(f"❌ Sample {trial_num:04d} failed: {e}")
        
        result = {
            "sample_id": trial_num,
            "component_name": f"fvf_sample_{trial_num:04d}",
            "success": False,
            "error": str(e),
            "execution_time": trial_time,
            "parameters": params
        }
        return result
    
    finally:
        # Clean up working directory
        cleanup_files()

def cleanup_files():
    """Clean up generated files in working directory"""
    files_to_clean = [
        "*.gds", "*.drc.rpt", "*.lvs.rpt", "*.ext", "*.spice", 
        "*.res.ext", "*.sim", "*.nodes", "*_lvsmag.spice", "*_sim.spice"
    ]
    
    for pattern in files_to_clean:
        import glob
        for file in glob.glob(pattern):
            try:
                os.remove(file)
            except OSError:
                pass

def main():
    """Main FVF dataset generation pipeline"""
    logger.info("🚀 Starting FVF Dataset Generation (360 samples)")
    
    # Load pre-generated parameters
    fvf_parameters = load_fvf_parameters()
    n_samples = len(fvf_parameters)
    
    # Configuration
    output_dir = "fvf_dataset_360"
    
    # Create output directory
    Path(output_dir).mkdir(exist_ok=True)
    
    # Save parameter configuration
    with open(Path(output_dir) / "fvf_parameters_used.json", 'w') as f:
        json.dump(fvf_parameters, f, indent=2)
    
    # Run evaluations
    results = []
    total_start = time.time()
    
    logger.info(f"📊 Processing {n_samples} FVF samples...")
    
    for i, params in enumerate(fvf_parameters, 1):
        result = run_single_evaluation(i, params, output_dir)
        results.append(result)
        
        # Progress updates
        if i % 10 == 0:
            success_rate = sum(1 for r in results if r["success"]) / len(results) * 100
            elapsed = time.time() - total_start
            estimated_total = elapsed * n_samples / i
            remaining = estimated_total - elapsed
            
            logger.info(f"📈 Progress: {i}/{n_samples} ({i/n_samples*100:.1f}%) - Success: {success_rate:.1f}% - ETA: {remaining/60:.1f}m")
    
    # Final summary
    total_time = time.time() - total_start
    successful = [r for r in results if r["success"]]
    success_rate = len(successful) / len(results) * 100
    
    logger.info(f"\n🎉 FVF Dataset Generation Complete!")
    logger.info(f"📊 Total time: {total_time/60:.1f} minutes")
    logger.info(f"📈 Success rate: {len(successful)}/{len(results)} ({success_rate:.1f}%)")
    
    if successful:
        drc_passes = sum(1 for r in successful if r["drc_pass"])
        lvs_passes = sum(1 for r in successful if r["lvs_pass"])
        avg_time = sum(r["execution_time"] for r in successful) / len(successful)
        
        logger.info(f"📋 Among successful samples:")
        logger.info(f"   DRC passes: {drc_passes}/{len(successful)} ({drc_passes/len(successful)*100:.1f}%)")
        logger.info(f"   LVS passes: {lvs_passes}/{len(successful)} ({lvs_passes/len(successful)*100:.1f}%)")
        logger.info(f"   Average time per sample: {avg_time:.1f}s")
    
    # Save detailed results
    results_file = Path(output_dir) / "fvf_results.json"
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    # Save summary CSV
    df_results = pd.DataFrame(results)
    summary_file = Path(output_dir) / "fvf_summary.csv"
    df_results.to_csv(summary_file, index=False)
    
    logger.info(f"📄 Results saved to: {results_file}")
    logger.info(f"📊 Summary saved to: {summary_file}")
    
    # Calculate estimated time for completion
    if successful:
        avg_time_per_sample = sum(r["execution_time"] for r in successful) / len(successful)
        estimated_total_time = avg_time_per_sample * n_samples / 3600  # in hours
        logger.info(f"⏱️ Estimated total completion time: {estimated_total_time:.1f} hours")
    
    if success_rate >= 90:
        logger.info("🎉 Excellent success rate! FVF dataset generation pipeline is robust.")
        return True
    else:
        logger.warning(f"⚠️ Success rate {success_rate:.1f}% below 90%. Review failures.")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        logger.info("✅ FVF dataset generation completed successfully!")
    else:
        logger.warning("❌ Review and fix issues in FVF dataset generation.")
